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

Storage services
==================
EBS -->block storage   EBS Additional storage capacity 16384GB
EFS -->file system
s3 --> object storage

storage types
==============
Block storage --> the data(file) will be spilt into a equally distributed blocks and save as ablocks in the storage.
advantage: performance, read and write performance.
EBS Additional storage capacity 16384GB
root EBS storage support 1023GB

IOPS--> input output operations seconds

file storage or file system --> treditional file systems,
it will maintain as single entity
either block storage or file storage we have to attach to the instance we have mount to the file system then only wecan use.

object storage --> we can access data from any where without mounting the storage to server.
                   each object which we will upload to object storage will have uniqueID and URL(HTTP(S)) endpoint.


create instance,automatically EBS it will store some default value,give lsblk it will show how many block storage have,root file system.
go to volume, create volume, give siz3 5 gb, select availability zone 1a, give tag name,create volume.
attch created volume, go to actions,select attach volume,select running instance,select attach volume.
then verfication go to ec2 instance, check volumes use coomand lsblk,it will show two volumes.
created new volume before use you need to format and if you want, do partions and mount the volume.
check file system in ec2 instance using command file -s /dev/xvdf it will show output dev/xvdf: data
check file system in ec2 instance using command file -s /dev/xvda1 it will show output /dev/xvda1: SGI XFS filesystem data (blksz 4096, inosz 512, v2 dirs)
create file system in ec2 instance using command like mkfs.ext4 /dev/xvdf and enter.
df -kh use this command volume mounted or not.create directory mkdir ebsdemo,mount coomand mount /dev/xvdf ebsdemo/
create a file vi ebsdemo/test.txt give comment,
in real time, jenkins storage in additional volume.
if you want add more volume, go to actions, select modify volume, give size 5 to 10 and give modify.
root volume and additional volume how to take backup, select this volume,create snapshot,give name for snapshot.


create additional volume and use
==================================
1)create EBS volume
2) Attach EBS Volume 
3) create a filesysytem (format)
ext3,ext4
4)Mount volume with directory (saving temporary)
5) save in fstab  (saving permenently)


restore data from the snapshot
==============================
1)create avolume
2) Attach volume 
3)mount that volume
4)save in fstab



what is the maximum capacity of 1 EBS Volume?
16TB or 16384 GB

can we change volume size & type while it is in use?
yes we can change, we can change the volume type. we can increase volume you no nedd to shutdown the server.

create volume from the snapshot can we do file system?
no, if i create again file sysytem data will be loss.

what is replication and migration?
replication--> duplicating maintain two servers, 
Migration --> we are moving one data center to another data center.


AWs infrstructure.
=======================
hardware --. cpu memory storage,networks
servers -->
on premise data centers
aws cloud provider it's providing infrstructure,servers,storage,networks,softewares.

Aws solution Architects
Aws sysops Engineers

how to attach snapshot to another server
=============================================
create one more instance in 1b availabityzone.login
from the snapshot create volume, go to snapshot,go to action, select create volume from snapshot and create.
go to voulmes, attach this volume, select 1b avilability zone,and create.
after attaching volume, mount the volume, before create one directory in 1b zone,mount /dev/xvdf bag/
file -s .dev/xvdf for checking file system.
cat bag/test.txt

need to create AMI old server then create new instance with new key?

how can we recover EC2 if you lost pem file?
not able to get recover old pem key.so instead of create one instance with new pem file,
login new ec2 insatnce, create volume with public key,attach volume, copy lates public key from old to new,after detach volume,
attach root volume, later we can do ssh with new key pair.if you want delete temporary server if you want.


NFS --> Network file system  port number-2049
EFS --> Elastic file system managed NFS 

search in services, EFS, and click on EFS, click create file system,give name EBS_Demo,
select network, create.
use client software EC2 nfs client or EFS client both instances.
we have to open the port for NFS in security groups.
open two instances,
need shared file sysytem,install efs or nfs file,yum install nfs-utils -y,df -kh for verification,
copy efs dns name fs-0f5cc10f05d85ba2f.efs.eu-west-1.amazonaws.com:/ efs,
create directory, mkdir shared,sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-0f5cc10f05d85ba2f.efs.eu-west-1.amazonaws.com:/ shared/
EFS limit scalable elastic file system no limit.


S3(Simple storage service)
===========================
s3 another kind of a storage we can use to store our data to maintain our data.
s3 is an object storage, we can access data from any where without mounting s3.
what ever our object(file) we upload to s3 will have unique id and endpoint(url), using which we can access from any where.

how can upload data to s3
====================================
progamatically we upload and access data using.
AWS CLI --> command line interface
AWS API --> application programming interface
AWS SDK --> software development kit.
            Boto -->AWS SDK for Python
            Boto3 --> AWS SDK for Python
AWS GUI(console)

S3 is perfect place to maintain static data of our applications.
Application Images,Documents, Videos.

Netflix,DropBox using s3 as data store.

s3 Bucket name should be unique across in the world


Security Group(Firewall)
VPc(Subnets,Rout Tables)
How to create s3 bucket
========================
login EC2 instance, search in services s3,create a bucket,give bucket name universal name like princy4321,select region where you want,
click on bucket,upload any file,by default data (ojects) is secure but you will not access,first give the pselect type s3,principal give *,actions get object select,
give amazon resource name.


By Default objects(files) are secure in s3
Security
ACL
Bucket Policies

s3
=====
1)scalability
2)Availability
3)internet
4)latency
==============================
1)S3 bucket setup
2) data upload to s3
3) data down load to s3
==============================
1.how to make an object public?


1.static website -->
2.dynamic website -->

2.how to enable static website hosting?

3.static website demo?

Regions
=========

Load Balancer
=============
mavenwebAppserversLoad Balance software
Ngnix
HAProxy
Appache HTTPD
Defaulut port of load balncers HTTP:80,HTPPS:443.


ELB --> Elastic Load balanceR,IT'S AWS Managed Service for Load Balancing.
setup 2 tomcat servers, deploy one application like maven-web-application,now create load balancer.

Create load balancer,map application server ip's in load balncer,
what is layer 7 and 4 load balncer?

1)Application load balncer -->Layer 7 support HTTP/HTPPS protocol
it support path based routing and host based routing

2)Network Load balncer-->Layer 4 Support TCP Protocol
it support port based routing port to port

3)classic Load balncer--> Legacy(old) port HTTP/HTTPS OR TCP

ELB
Listners --> will listen request on specific protocol and port.
htpp-80
each listner we can define routing rules so that it will route the traffic to appropriate targetgroups.
https-443

Routing rules
Target groups --> it's logical grouping of our servers.


create target group from ec2 instance
========================================
create target group,give target groupname like mavenwebapplication,give protocol,
http,and port 8080, give vpc, click next, select two servers add,create target troup.

Now create loadbalncer,selct load balncer,select applcation load balncer,click create,
selcet interbet-facing,give load balncer port numberhttp 80,https 443,selct availablity zones,1a,1b,

mavenwebAppservers

path based routin-
host based routin-


Auto Scaling
============
Min --> Based on requirement we can have min number servers defined.
Max --> we can define max servers

AutoscalingGroup --> we can create autoscaling by defining MIN,MAX servers required for our application to handle the load.

Launch Configuration --> It's an input for ASG, ASG will use launch configuration to create ec2 instances, 
                         Launch config will have information about instance type,AMI,userdata,SSHKey, sg,.etc.
                         
Scaling Polocies  --> we can define how to scale when to scale.
                      Manual Scaling 
                      Dyanmic scaling --> Based on the Metrics(CPU,Memory) we can scale upor we can scale down servers.
                      Schduled

healthchecks -->

Golden image --> we can create our own AMI which has software configuratons and application.



VPC
========
VPC --> Virtual private cloud,it's a private network in which we will create our aws resources.
and we will have complete control on the network and it's routing.


subnets --> subnetworks
private subnet --> a network which does not have accesss to the internet(WAN).
so these servers which are created under private network will not have access to internet and we pepole cannot access the private subnet
servers from internet. but servers which are part of same vpc (LAN Network) can talk to each other with internet.
public subnet --> a network which has route or access to the internet. servers will have public in this network.
servers will have access to the internet. people can access these servers from internet.

Application servers
DB servers
load balnces (web servers)
k8' servers

IGW --> internet gate way, it's virtual router which will enabled internet connectivity our vpc.

Route Tables --> 

By default when we create AWS account we will have a default vpc.

CIDR --> Classless inter domain routing it's an alogirtham using which we can define our network range and it's routing.
172.31.0.0/16
           siuder block

how many vpc create in one region?
5


================================================================================================================================================
IAM
======
IAM --> Identity Access Management

Authentication and Autheraization

Groups --> we can create a group can attach polocies to the group. we can assing users(Developers,Admins) to the group.
Policies
EC2 Read only Access
EC2FullAccess
vpc read only access
vpc full access
eks readonly access
ecrreadonlyaccess
ecr full access
iam ready only access
IAM full access
s3 readonly
s3 full access
Users
Roles --> Roles can be create with some polocies based on requirement. we can attach role to aws resource like EC2,EKS ..etc. 
they can manage aws resources programatically base the polices
AWS Resources/workloads --> EC2, ELB, EBS, VPC, S3,EFS,EKS,ECR

Developers
AWS Admin
AWS Architects
Devops

how many ways we can manage (access/create/update/delete) AWS?
1) AWS Console GUI(Graphical user interface) 
2) AWS CLI
3) AWS API
4) AWS SDK
other development tools like
terraform -->infrastructure as a code

Create IAM User
---------------
go to services page, search IAM, click IAM,
create a Group,give group name DevOps,attch policies,





